# Ollama Configuration
# The base URL where your Ollama server is running
OLLAMA_BASE_URL=http://localhost:11434

# The model to use from Ollama
# Examples: llama3.1:8b, llama3.1:70b, codellama:13b, etc.
OLLAMA_MODEL=llama3.1:8b

# OpenAI API Configuration (for Cloud API)
# The base URL for the OpenAI API or compatible API
OPENAI_API_BASE="https://dashscope.aliyuncs.com/compatible-mode/v1"

# Your OpenAI API key
OPENAI_API_KEY="sk-0180e5edde404ada88f3a6f5d1569d6d"

# The model to use from OpenAI API
# Examples: gpt-4, gpt-4-turbo, gpt-3.5-turbo, etc.
OPENAI_MODEL="qwen-flash"

# GitHub Personal Access Token (for MCP tools)
# GITHUB_PERSONAL_ACCESS_TOKEN=your_github_token_here